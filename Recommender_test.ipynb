{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from recommender import Recommender\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic import BERTopic\n",
    "import umap\n",
    "import hdbscan\n",
    "from octis.evaluation_metrics.diversity_metrics import TopicDiversity\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from pylatexenc.latex2text import LatexNodes2Text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "transformers.set_seed(42)\n",
    "tqdm.pandas()\n",
    "df = pd.read_csv('best_arxiv.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "model_name = 'all-mpnet-base-v2'\n",
    "# sentence_model = SentenceTransformer(model_name, device=\"cuda\")\n",
    "# embeddings = np.array([sentence_model.encode(x) for x in tqdm(df['abstract'].tolist())])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# np.save('embeddings_for_arxiv.npy', embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Getting recommendations:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5d2f1ab46324427a8d03392cbdca88d9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "{'black hole': ['  We demonstrate that cosmic string loops may provide a joint resolution of two\\nmysteries surrounding recently observed black holes. For a string tension in an\\nappropriate range, large radius string loops have the potential to provide the\\nnonlinearities in the early universe which seed supermassive black holes. The\\nmore numerous smaller radius string loops can then seed intermediate mass black\\nholes, including those with a mass in the region between 65 and 135 solar\\nmasses in which standard black hole formation scenarios predict no black holes\\nare able to form, but which have recently been detected by the LIGO/VIRGO\\ncollaboration. We find that there could be as many as $10^6$ of intermediate\\nmass black holes per galaxy, providing a tantalizing target for gravitational\\nwave observatories to look for.\\n',\n  '  Gravitational slingshots around a neutron star in a compact binary have been\\nproposed as a means of accelerating large masses to potentially relativistic\\nspeeds. Such a slingshot is attractive since fuel is not expended for the\\nacceleration, however it does entail a spacecraft diving into close proximity\\nof the binary, which could be hazardous. It is proposed here that such a\\nslingshot can be performed remotely using a beam of light which follows a\\nboomerang null geodesic. Using a moving black hole as a gravitational mirror,\\nkinetic energy from the black hole is transferred to the beam of light as a\\nblueshift and upon return the recycled photons not only accelerate, but also\\nadd energy to, the spacecraft. It is shown here that this gained energy can be\\nlater expended to reach a terminal velocity of approximately 133% the velocity\\nof the black hole. A civilization could exploit black holes as galactic way\\npoints but would be difficult to detect remotely, except for an elevated binary\\nmerger rate and excess binary eccentricity.\\n',\n  '  In this second part of a two-part paper, we discuss numerical simulations of\\na head-on merger of two non-spinning black holes. We resolve the fate of the\\noriginal two apparent horizons by showing that after intersecting, their world\\ntubes \"turn around\" and continue backwards in time. Using the method presented\\nin the first paper to locate these surfaces, we resolve several such world\\ntubes evolving and connecting through various bifurcations and annihilations.\\nThis also draws a consistent picture of the full merger in terms of apparent\\nhorizons, or more generally, marginally outer trapped surfaces (MOTSs). The\\nMOTS stability operator provides a natural mechanism to identify MOTSs which\\nshould be thought of as black hole boundaries. These are the two initial ones\\nand the final remnant. All other MOTSs lie in the interior and are neither\\nstable nor inner trapped.\\n'],\n 'deep learning': ['  In this work, we study an optimizer, Grad-Avg to optimize error functions. We\\nestablish the convergence of the sequence of iterates of Grad-Avg\\nmathematically to a minimizer (under boundedness assumption). We apply Grad-Avg\\nalong with some of the popular optimizers on regression as well as\\nclassification tasks. In regression tasks, it is observed that the behaviour of\\nGrad-Avg is almost identical with Stochastic Gradient Descent (SGD). We present\\na mathematical justification of this fact. In case of classification tasks, it\\nis observed that the performance of Grad-Avg can be enhanced by suitably\\nscaling the parameters. Experimental results demonstrate that Grad-Avg\\nconverges faster than the other state-of-the-art optimizers for the\\nclassification task on two benchmark datasets.\\n',\n  '  Machine learning algorithms typically perform optimization over a class of\\nnon-convex functions. In this work, we provide bounds on the fundamental\\nhardness of identifying the global minimizer of a non convex function.\\nSpecifically, we design a family of parametrized non-convex functions and\\nemploy statistical lower bounds for parameter estimation. We show that the\\nparameter estimation problem is equivalent to the problem of function\\nidentification in the given family. We then claim that non convex optimization\\nis at least as hard as function identification. Jointly, we prove that any\\nfirst order method can take exponential time to converge to a global minimizer.\\n',\n  '  We introduce a novel and efficient algorithm called the stochastic\\napproximate gradient descent (SAGD), as an alternative to the stochastic\\ngradient descent for cases where unbiased stochastic gradients cannot be\\ntrivially obtained. Traditional methods for such problems rely on\\ngeneral-purpose sampling techniques such as Markov chain Monte Carlo, which\\ntypically requires manual intervention for tuning parameters and does not work\\nefficiently in practice. Instead, SAGD makes use of the Langevin algorithm to\\nconstruct stochastic gradients that are biased in finite steps but accurate\\nasymptotically, enabling us to theoretically establish the convergence\\nguarantee for SAGD. Inspired by our theoretical analysis, we also provide\\nuseful guidelines for its practical implementation. Finally, we show that SAGD\\nperforms well experimentally in popular statistical and machine learning\\nproblems such as the expectation-maximization algorithm and the variational\\nautoencoders.\\n'],\n 'dogs': ['  The available minima timings of 14 selected eclipsing binaries (V1297 Cas, HD\\n24105, KU Aur, GU CMa, GH Mon, AZ Vel, DI Lyn, DK Her, GQ Dra, V624 Her, V1134\\nHer, KIC 6187893, V1928 Aql, V2486 Cyg) were collected and analyzed. Using the\\nautomatic telescopes, surveys, and satellite data, we derived more than 2500\\ntimes of eclipses, accompanied with our own ground-based observations. These\\ndata were used to detect the period variations in these multiple systems. The\\neclipse timing variations were described using the third-body hypothesis and\\nthe light-time effect. Their respective periods were derived as 2.5, 16.2, 27,\\n20, 64, 5.6, 22, 115, 27, 42, 6.9, 11.2, 4.1, and 8.4 years for these systems,\\nrespectively. The predicted minimal mass of the third body was calculated for\\neach of the systems, and we discuss here their prospective detectability. The\\nlight curves of HD 24105, GH Mon, DK Her, V1134 Her, KIC 6187893, V1928 Aql,\\nand V2486 Cyg were analyzed using the PHOEBE program, resulting in physical\\nparameters of the components. Significant fractions of the third light were\\ndetected during the light-curve analysis, supporting our hypothesis of the\\ntriple-star nature of all these systems. The majority of these systems (nine\\nout of 14) were already known as visual doubles. Our study shifts them to\\npossible quadruples, what makes them even more interesting.\\n',\n  '  We present an extensive study of 162 early-type binary systems located in the\\nLMC galaxy that show apsidal motion and have never been studied before. For the\\nample systems, we performed light curve and apsidal motion modelling for the\\nfirst time. These systems have a median orbital period of 2.2 days and typical\\nperiods of the apsidal motion were derived to be of the order of decades. We\\nidentified two record-breaking systems. The first, OGLE LMC-ECL-22613, shows\\nthe shortest known apsidal motion period among systems with main sequence\\ncomponents (6.6 years); it contains a third component with an orbital period of\\n23 years. The second, OGLE LMC-ECL-17226, is an eccentric system with the\\nshortest known orbital period (0.9879 days) and with quite fast apsidal motion\\nperiod (11 years). Among the studied systems, 36 new triple-star candidates\\nwere identified based on the additional period variations. This represents more\\nthan 20% of all studied systems, which is in agreement with the statistics of\\nmultiples in our Galaxy. However, the fraction should only be considered as a\\nlower limit of these early-type stars in the LMC because of our method of\\ndetection, data coverage, and limited precision of individual times of\\neclipses.\\n',\n  '  We analyze two binary systems containing giant stars, V723 Mon (\"the\\nUnicorn\") and 2M04123153+6738486 (\"the Giraffe\"). Both giants orbit more\\nmassive but less luminous companions, previously proposed to be mass-gap black\\nholes. Spectral disentangling reveals luminous companions with star-like\\nspectra in both systems. Joint modeling of the spectra, light curves, and\\nspectral energy distributions robustly constrains the masses, temperatures, and\\nradii of both components: the primaries are luminous, cool giants ($T_{\\\\rm\\neff,\\\\,giant} = 3,800\\\\,\\\\rm K$ and $4,000\\\\,\\\\rm K$, $R_{\\\\rm giant}=\\n22.5\\\\,R_{\\\\odot}$ and $25\\\\,R_{\\\\odot}$) with exceptionally low masses ($M_{\\\\rm\\ngiant} \\\\approx 0.4\\\\,M_{\\\\odot}$) that likely fill their Roche lobes. The\\nsecondaries are only slightly warmer subgiants ($T_{\\\\rm eff,\\\\,2} = 5,800\\\\,\\\\rm\\nK$ and $5,150\\\\,\\\\rm K$, $R_2= 8.3\\\\,R_{\\\\odot}$ and $9\\\\,R_{\\\\odot}$) and thus are\\nconsistent with observed UV limits that would rule out main-sequence stars with\\nsimilar masses ($M_2 \\\\approx 2.8\\\\,M_{\\\\odot}$ and $\\\\approx 1.8\\\\,M_{\\\\odot}$). In\\nthe Unicorn, rapid rotation blurs the spectral lines of the subgiant, making it\\nchallenging to detect even at wavelengths where it dominates the total light.\\nBoth giants have surface abundances indicative of CNO processing and subsequent\\nenvelope stripping. The properties of both systems can be reproduced by binary\\nevolution models in which a $1-2\\\\,M_{\\\\odot}$ primary is stripped by a companion\\nas it ascends the giant branch. The fact that the companions are also evolved\\nimplies either that the initial mass ratio was very near unity, or that the\\ncompanions are temporarily inflated due to rapid accretion. The Unicorn and\\nGiraffe offer a window into into a rarely-observed phase of binary evolution\\npreceding the formation of wide-orbit helium white dwarfs, and eventually,\\ncompact binaries containing two helium white dwarfs.\\n']}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsys = Recommender(model_name, df['abstract_uncleaned'].tolist(), df['topics'].tolist(),\n",
    "                   embeddings_file='embeddings_for_arxiv.npy',\n",
    "                   model_path='best_model_arxiv')\n",
    "result = rsys.recommend(['black hole', 'deep learning', 'dogs'])\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "Getting recommendations:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "79f2a15f14554644a3509c58c86380b0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "{'materials': ['  Expanding on our former hypothesis that, in the current information age,\\nteaching physics should become more intuition-based and aiming at pattern\\nrecognition skills, we present multiple examples of qualitative methods in\\ncondensed matter physics. They include the subjects of phonons, thermal and\\nelectronic properties of matter, electron-phonon interactions and some\\nproperties of semiconductors.\\n',\n  \"  A major motivation for the scientific study of artworks is to understand\\ntheir states of preservation and ongoing degradation mechanisms. This enables\\npreservation strategies to be developed for irreplaceable works. Intensely-hued\\ncadmium sulphide (CdS) yellow pigments are of particular interest because these\\nare key to the palettes of many important late 19th and early 20th century\\nmasters, including Vincent Van Gogh, Pablo Picasso, Henri Matisse, and Edvard\\nMunch. As these paintings age, their cadmium yellow paints are undergoing\\nsevere fading, flaking, and discolouration. These effects are associated with\\nphotodegradation, the light-facilitated reactions of CdS with oxygen, moisture,\\nand even the paint binding medium. The use of common optical and X-ray methods\\nto characterize the physical state of the pigment is challenging due to the\\nmixing of the various components of the paint at length scales smaller than\\ntheir resolution. Here, we present an atomic-scale structural and chemical\\nanalysis of the CdS pigment in Edvard Munch's The Scream (c. 1910, Munch\\nMuseet), enabled by new electron microscope detector technologies. We show that\\nthe CdS pigment consists of clusters of defective nanoparticles ~5-10 nm in\\ndiameter. It is known from the modern use of such particles in photocatalysis\\nthat they are inherently vulnerable to photodegradation. Chlorine doping and a\\npolytype crystal structure further enhance the sensitivity of the CdS pigment\\nto photodegradation. In addition to The Scream, we have also observed this\\ninherently unstable pigment structure in Henri Matisse's Flower Piece (1906,\\nBarnes Foundation). The fundamental understanding of the pigments' nanoscale\\nstructures and impurities described here can now be used to predict which\\npaintings are most at risk of photooxidation, and guide the most effective\\npreservation strategies for iconic masterpieces.\\n\",\n  '  Materials with an intrinsic (ultra)low lattice thermal conductivity (k$_L$)\\nare critically important for the development of efficient energy conversion\\ndevices. In the present work, we have investigated microscopic origins of low\\nk$_L$ behavior in BaO, BaS and MgTe by exploring lattice dynamics and phonon\\ntransport of 16 iso-structural MX (Mg, Ca, Sr, Ba and X = O, S, Se and Te)\\ncompounds in the rocksalt (NaCl)-type structure by comparing their lattice\\ntransport properties with the champion thermoeletric iso-structural material,\\nPbTe. Anomalous trends are observed for k$_L$ in MX compounds except the MgX\\nseries in contrast to the expected trend from their atomic mass. The underlying\\nmechanisms for such low k$_L$ behavior in relatively low atomic mass systems\\nnamely BaO, BaS and MgTe compounds are thoroughly analyzed. We propose the\\nfollowing dominant factors that might be responsible for low k$_L$ behavior in\\nthese materials: 1) softening of transverse acoustic (TA) phonon modes despite\\nlow atomic mass, 2) low lying optic (LLO) phonon modes fall deep into acoustic\\nmode region which enhances overlap between longitudinal acoustic (LA) and LLO\\nphonon modes which increases scattering phase space, 3) short phonon lifetimes\\nand high scattering rates, 4) relatively high density (\\\\r{ho}) and large\\nGr\\\\\"uneisen parameter. Moreover, tensile strain also causes a further reduction\\nin k$_L$ for BaO, BaS and MgTe through phonon softening and near ferroelectric\\ninstability. Our comprehensive study on 16 binary MX compounds might provide a\\npathway for designing (ultra)low k$_L$ materials even with simple crystal\\nsystems through phonon engineering.\\n'],\n 'machine learning': ['  Machine learning algorithms typically perform optimization over a class of\\nnon-convex functions. In this work, we provide bounds on the fundamental\\nhardness of identifying the global minimizer of a non convex function.\\nSpecifically, we design a family of parametrized non-convex functions and\\nemploy statistical lower bounds for parameter estimation. We show that the\\nparameter estimation problem is equivalent to the problem of function\\nidentification in the given family. We then claim that non convex optimization\\nis at least as hard as function identification. Jointly, we prove that any\\nfirst order method can take exponential time to converge to a global minimizer.\\n',\n  '  Lecture notes on optimization for machine learning, derived from a course at\\nPrinceton University and tutorials given in MLSS, Buenos Aires, as well as\\nSimons Foundation, Berkeley.\\n',\n  '  In this work, we study an optimizer, Grad-Avg to optimize error functions. We\\nestablish the convergence of the sequence of iterates of Grad-Avg\\nmathematically to a minimizer (under boundedness assumption). We apply Grad-Avg\\nalong with some of the popular optimizers on regression as well as\\nclassification tasks. In regression tasks, it is observed that the behaviour of\\nGrad-Avg is almost identical with Stochastic Gradient Descent (SGD). We present\\na mathematical justification of this fact. In case of classification tasks, it\\nis observed that the performance of Grad-Avg can be enhanced by suitably\\nscaling the parameters. Experimental results demonstrate that Grad-Avg\\nconverges faster than the other state-of-the-art optimizers for the\\nclassification task on two benchmark datasets.\\n'],\n 'economy': [\"  This paper suggests that business cycles may be a manifestation of coupled\\nreal economy and stock market dynamics and describes a mechanism that can\\ngenerate economic fluctuations consistent with observed business cycles. To\\nthis end, we seek to incorporate into the macroeconomic framework a dynamic\\nstock market model based on opinion interactions (Gusev et al., 2015). We\\nderive this model from microfoundations, provide its empirical verification,\\ndemonstrate that it contains the efficient market as a particular regime and\\nestablish a link through which macroeconomic models can be attached for the\\nstudy of real economy and stock market interaction. To examine key effects, we\\nlink it with a simple macroeconomic model (Blanchard, 1981). The coupled system\\ngenerates nontrivial endogenous dynamics, which exhibit deterministic and\\nstochastic features, producing quasiperiodic fluctuations (business cycles). We\\nalso inspect this system's behavior in the phase space. The real economy and\\nthe stock market coevolve dynamically along the path governed by a\\nstochastically-forced dynamical system with two stable equilibria, one where\\nthe economy expands and the other where it contracts, resulting in business\\ncycles identified as the coherence resonance phenomenon. Thus, the\\nincorporation of stock market dynamics into the macroeconomic framework, as\\npresented here, allows the derivation of realistic behaviors in a tractable\\nsetting.\\n\",\n  '  Sentiment analysis as a sub-field of natural language processing has received\\nincreased attention in the past decade enabling organisations to more\\neffectively manage their reputation through online media monitoring. Many\\ndrivers impact reputation, however, this thesis focuses only the aspect of\\nfinancial performance and explores the gap with regards to financial sentiment\\nanalysis in a South African context. Results showed that pre-trained sentiment\\nanalysers are least effective for this task and that traditional lexicon-based\\nand machine learning approaches are best suited to predict financial sentiment\\nof news articles. The evaluated methods produced accuracies of 84\\\\%-94\\\\%. The\\npredicted sentiments correlated quite well with share price and highlighted the\\npotential use of sentiment as an indicator of financial performance. A main\\ncontribution of the study was updating an existing sentiment dictionary for\\nfinancial sentiment analysis. Model generalisation was less acceptable due to\\nthe limited amount of training data used. Future work includes expanding the\\ndata set to improve general usability and contribute to an open-source\\nfinancial sentiment analyser for South African data.\\n',\n  '  This paper uses new and recently introduced mathematical techniques to\\nundertake a data-driven study on the systemic nature of global inflation. We\\nstart by investigating country CPI inflation over the past 70 years. There, we\\nhighlight the systemic nature of global inflation with a judicious application\\nof eigenvalue analysis and determine which countries exhibit most \"centrality\"\\nwith an inner-product based optimization method. We then turn to inflationary\\nimpacts on financial market securities, where we explore country equity\\nindices\\' equity robustness and the varied performance of equity sectors during\\nperiods of significant inflationary pressure. Finally, we implement a\\ntime-varying portfolio optimization to determine which asset classes were most\\nbeneficial in increasing portfolio Sharpe ratio when an investor must hold a\\ncore (and constant) allocation to equities.\\n']}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = rsys.recommend(['materials', 'machine learning', 'economy'])\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "Getting recommendations:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "262a2dfbebf7488a91a783177420ab00"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "{'covid': ['  Solid estimates describing the clinical course of SARS-CoV-2 infections are\\nstill lacking due to under-ascertainment of asymptomatic and mild-disease\\ncases. In this work, we quantify age-specific probabilities of transitions\\nbetween stages defining the natural history of SARS-CoV-2 infection from 1,965\\nSARS-CoV-2 positive individuals identified in Italy between March and April\\n2020 among contacts of confirmed cases. Infected contacts of cases were\\nconfirmed via RT-PCR tests as part of contact tracing activities or\\nretrospectively via IgG serological tests and followed-up for symptoms and\\nclinical outcomes. In addition, we provide estimates of time intervals between\\nkey events defining the clinical progression of cases as obtained from a larger\\nsample, consisting of 95,371 infections ascertained between February and July\\n2020. We found that being older than 60 years of age was associated with a\\n39.9% (95%CI: 36.2-43.6%) likelihood of developing respiratory symptoms or\\nfever >= 37.5 {\\\\deg}C after SARS-CoV-2 infection; the 22.3% (95%CI: 19.3-25.6%)\\nof the infections in this age group required hospital care and the 1% (95%CI:\\n0.4-2.1%) were admitted to an intensive care unit (ICU). The corresponding\\nproportions in individuals younger than 60 years were estimated at 27.9%\\n(95%CI: 25.4-30.4%), 8.8% (95%CI: 7.3-10.5%) and 0.4% (95%CI: 0.1-0.9%),\\nrespectively. The infection fatality ratio (IFR) ranged from 0.2% (95%CI:\\n0.0-0.6%) in individuals younger than 60 years to 12.3% (95%CI: 6.9-19.7%) for\\nthose aged 80 years or more; the case fatality ratio (CFR) in these two age\\nclasses was 0.6% (95%CI: 0.1-2%) and 19.2% (95% CI: 10.9-30.1%), respectively.\\nThe median length of stay in hospital was 10 (IQR 3-21) days; the length of\\nstay in ICU was 11 (IQR 6-19) days. The obtained estimates could be\\ninstrumental to refine mathematical modeling work supporting public health\\ndecisions.\\n',\n  '  In late December 2019, a novel strand of Coronavirus (SARS-CoV-2) causing a\\nsevere, potentially fatal respiratory syndrome (COVID-19) was identified in\\nWuhan, Hubei Province, China and is causing outbreaks in multiple world\\ncountries, soon becoming a pandemic. Italy has now become the most hit country\\noutside of Asia: on March 16, 2020, the Italian Civil Protection documented a\\ntotal of 27980 confirmed cases and 2158 deaths of people tested positive for\\nSARS-CoV-2. In the context of an emerging infectious disease outbreak, it is of\\nparamount importance to predict the trend of the epidemic in order to plan an\\neffective control strategy and to determine its impact. This paper proposes a\\nnew epidemic model that discriminates between infected individuals depending on\\nwhether they have been diagnosed and on the severity of their symptoms. The\\ndistinction between diagnosed and non-diagnosed is important because\\nnon-diagnosed individuals are more likely to spread the infection than\\ndiagnosed ones, since the latter are typically isolated, and can explain\\nmisperceptions of the case fatality rate and of the seriousness of the epidemic\\nphenomenon. Being able to predict the amount of patients that will develop\\nlife-threatening symptoms is important since the disease frequently requires\\nhospitalisation (and even Intensive Care Unit admission) and challenges the\\nhealthcare system capacity. We show how the basic reproduction number can be\\nredefined in the new framework, thus capturing the potential for epidemic\\ncontainment. Simulation results are compared with real data on the COVID-19\\nepidemic in Italy, to show the validity of the model and compare different\\npossible predicted scenarios depending on the adopted countermeasures.\\n',\n  '  An epidemiological model for COVID-19 was developed and implemented in\\nMATLAB/GNU Octave for use by public health practitioners, policy makers and the\\ngeneral public. The model distinguishes four stages in the disease: infected,\\nsick, seriously sick, and better. The model was preliminarily parameterized\\nbased on observations of the spread of the disease. The model is consistent\\nwith a mortality rate of 1.5 %. Preliminary simulations with the model indicate\\nthat concepts such as \"herd immunity\" and \"flattening the curve\" are highly\\nmisleading in the context of this virus. Public policies based on these\\nconcepts are inadequate to protect the population. Only reducing the R0 of the\\nvirus below 1 is an effective strategy for maintaining the death burden of\\nCOVID-19 within the normal range of seasonal flu. As R0 values estimated with\\nthe model range from 2.82 worldwide outside of China and 3.83 in the Western\\nworld in late February - early March 2020, this means social distancing with\\neffectiveness greater than 65 % (worldwide) or 75 % (Western world) are needed\\nto combat the virus successfully.\\n']}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = rsys.recommend(['covid'])\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "Getting recommendations:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b4bf396e455543a69ea4a9c7f2fc5f7e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "{'animal': ['  We present LSeg, a novel model for language-driven semantic image\\nsegmentation. LSeg uses a text encoder to compute embeddings of descriptive\\ninput labels (e.g., \"grass\" or \"building\") together with a transformer-based\\nimage encoder that computes dense per-pixel embeddings of the input image. The\\nimage encoder is trained with a contrastive objective to align pixel embeddings\\nto the text embedding of the corresponding semantic class. The text embeddings\\nprovide a flexible label representation in which semantically similar labels\\nmap to similar regions in the embedding space (e.g., \"cat\" and \"furry\"). This\\nallows LSeg to generalize to previously unseen categories at test time, without\\nretraining or even requiring a single additional training sample. We\\ndemonstrate that our approach achieves highly competitive zero-shot performance\\ncompared to existing zero- and few-shot semantic segmentation methods, and even\\nmatches the accuracy of traditional segmentation algorithms when a fixed label\\nset is provided. Code and demo are available at\\nhttps://github.com/isl-org/lang-seg.\\n',\n  \"  Camouflaged objects are generally difficult to be detected in their natural\\nenvironment even for human beings. In this paper, we propose a novel\\nbio-inspired network, named the MirrorNet, that leverages both instance\\nsegmentation and mirror stream for the camouflaged object segmentation.\\nDifferently from existing networks for segmentation, our proposed network\\npossesses two segmentation streams: the main stream and the mirror stream\\ncorresponding with the original image and its flipped image, respectively. The\\noutput from the mirror stream is then fused into the main stream's result for\\nthe final camouflage map to boost up the segmentation accuracy. Extensive\\nexperiments conducted on the public CAMO dataset demonstrate the effectiveness\\nof our proposed network. Our proposed method achieves 89% in accuracy,\\noutperforming the state-of-the-arts.\\n  Project Page: https://sites.google.com/view/ltnghia/research/camo\\n\",\n  '  In this paper, we are concerned with the detection of a particular type of\\nobjects with extreme aspect ratios, namely \\\\textbf{slender objects}. In\\nreal-world scenarios, slender objects are actually very common and crucial to\\nthe objective of a detection system. However, this type of objects has been\\nlargely overlooked by previous object detection algorithms. Upon our\\ninvestigation, for a classical object detection method, a drastic drop of\\n$18.9\\\\%$ mAP on COCO is observed, if solely evaluated on slender objects.\\nTherefore, we systematically study the problem of slender object detection in\\nthis work. Accordingly, an analytical framework with carefully designed\\nbenchmark and evaluation protocols is established, in which different\\nalgorithms and modules can be inspected and compared. \\\\New Our study reveals\\nthat effective slender object detection can be achieved ~\\\\textbf{with none of}\\n(1) anchor-based localization; (2) specially designed box representations.\\nInstead, \\\\textbf{the critical aspect of improving slender object detection is\\nfeature adaptation}. It identifies and extends the insights of existing methods\\nthat are previously underexploited. Furthermore, we propose a feature adaption\\nstrategy that achieves clear and consistent improvements over current\\nrepresentative object detection methods.\\n']}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = rsys.recommend(['animal'])\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}